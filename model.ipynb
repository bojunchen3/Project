{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ-pZvQa6W8-",
        "outputId": "b552dc39-590b-4c7b-9d5a-8bb625381986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOvUjGal71zA",
        "outputId": "4cc00650-e291-426c-fe8c-359051d3d1e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All OK\n"
          ]
        }
      ],
      "source": [
        "!pip install larq\n",
        "!pip uninstall sklearn\n",
        "!pip install pretty_confusion_matrix\n",
        "%mkdir dataset\n",
        "%cd /content/drive/MyDrive/project\n",
        "!unrar x /content/drive/MyDrive/project/dataset.rar -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcYpqMY36fBU",
        "outputId": "759867d3-d927-4a01-b737-e5176ed3c218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 10 classes.\n",
            "Found 1000 images belonging to 10 classes.\n",
            "Training ---------------------------------\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.8435 - accuracy: 0.6660\n",
            "Epoch 1: val_accuracy improved from -inf to 0.72600, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 30s 178ms/step - loss: 1.8435 - accuracy: 0.6660 - val_loss: 1.3162 - val_accuracy: 0.7260 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.9164\n",
            "Epoch 2: val_accuracy improved from 0.72600 to 0.77600, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 8s 196ms/step - loss: 0.3312 - accuracy: 0.9164 - val_loss: 1.6250 - val_accuracy: 0.7760 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9720\n",
            "Epoch 3: val_accuracy improved from 0.77600 to 0.86500, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 8s 202ms/step - loss: 0.0992 - accuracy: 0.9720 - val_loss: 0.7130 - val_accuracy: 0.8650 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9828\n",
            "Epoch 4: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 7s 160ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 2.1351 - val_accuracy: 0.7150 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1823 - accuracy: 0.9555\n",
            "Epoch 5: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 8s 206ms/step - loss: 0.1820 - accuracy: 0.9556 - val_loss: 1.4575 - val_accuracy: 0.7760 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9702\n",
            "Epoch 6: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 157ms/step - loss: 0.1045 - accuracy: 0.9702 - val_loss: 1.3805 - val_accuracy: 0.7730 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9878\n",
            "Epoch 7: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 1.2726 - val_accuracy: 0.8180 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9922\n",
            "Epoch 8: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 1.0534 - val_accuracy: 0.8310 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9906\n",
            "Epoch 9: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 156ms/step - loss: 0.0332 - accuracy: 0.9906 - val_loss: 0.9499 - val_accuracy: 0.8250 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9808\n",
            "Epoch 10: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 9s 215ms/step - loss: 0.0951 - accuracy: 0.9808 - val_loss: 2.9042 - val_accuracy: 0.6120 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9646\n",
            "Epoch 11: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 7s 174ms/step - loss: 0.1293 - accuracy: 0.9646 - val_loss: 0.8343 - val_accuracy: 0.8430 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9894\n",
            "Epoch 12: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 8s 195ms/step - loss: 0.0451 - accuracy: 0.9894 - val_loss: 8.3556 - val_accuracy: 0.2360 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9952\n",
            "Epoch 13: val_accuracy improved from 0.86500 to 0.92000, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 8s 204ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.4596 - val_accuracy: 0.9200 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9752\n",
            "Epoch 14: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 6s 158ms/step - loss: 0.0850 - accuracy: 0.9752 - val_loss: 0.9158 - val_accuracy: 0.8440 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9906\n",
            "Epoch 15: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 8s 190ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.9127 - val_accuracy: 0.8420 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9956\n",
            "Epoch 16: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 0.8420 - val_accuracy: 0.8810 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9776\n",
            "Epoch 17: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 8s 195ms/step - loss: 0.0838 - accuracy: 0.9776 - val_loss: 9.1600 - val_accuracy: 0.2050 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9816\n",
            "Epoch 18: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 7s 170ms/step - loss: 0.0699 - accuracy: 0.9816 - val_loss: 8.1392 - val_accuracy: 0.3050 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9942\n",
            "Epoch 19: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 7s 173ms/step - loss: 0.0133 - accuracy: 0.9942 - val_loss: 0.6708 - val_accuracy: 0.8930 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9966\n",
            "Epoch 20: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 8s 194ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.8731 - val_accuracy: 0.8750 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9982\n",
            "Epoch 21: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.5131 - val_accuracy: 0.9150 - lr: 0.0050\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9896\n",
            "Epoch 22: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 8s 191ms/step - loss: 0.0484 - accuracy: 0.9896 - val_loss: 0.9298 - val_accuracy: 0.8530 - lr: 0.0050\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9910\n",
            "Epoch 23: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 6s 162ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.8285 - val_accuracy: 0.8670 - lr: 0.0050\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9950\n",
            "Epoch 24: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 9s 217ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 1.2643 - val_accuracy: 0.8170 - lr: 0.0050\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9974\n",
            "Epoch 25: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.6417 - val_accuracy: 0.8930 - lr: 0.0050\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9882\n",
            "Epoch 26: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 8s 192ms/step - loss: 0.0494 - accuracy: 0.9882 - val_loss: 1.5158 - val_accuracy: 0.7860 - lr: 0.0050\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9950\n",
            "Epoch 27: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 1.1869 - val_accuracy: 0.8310 - lr: 0.0050\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9976\n",
            "Epoch 28: val_accuracy did not improve from 0.92000\n",
            "40/40 [==============================] - 8s 213ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.8425 - val_accuracy: 0.8460 - lr: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.layers import Softmax, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model, Sequential\n",
        "from larq.layers import QuantConv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "# 導入資料集\n",
        "train = ImageDataGenerator(rescale=1/255)\n",
        "val = ImageDataGenerator(rescale=1/255)\n",
        "train_dataset = train.flow_from_directory('/content/dataset/train/',\n",
        "                      target_size=(94,94),\n",
        "                      batch_size=128,\n",
        "                      color_mode='grayscale',\n",
        "                      class_mode='categorical')\n",
        "val_dataset = val.flow_from_directory('/content/dataset/validation/',\n",
        "                    target_size=(94,94),\n",
        "                    batch_size=128,\n",
        "                    color_mode='grayscale',\n",
        "                    class_mode='categorical')\n",
        "kwargs = dict(kernel_quantizer=\"ste_sign\",\n",
        "        kernel_constraint=\"weight_clip\")\n",
        "# 定義模型架構\n",
        "model = Sequential()\n",
        "model.add(QuantConv2D(filters=16, kernel_size=(3, 3), input_shape=(94, 94, 1), **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=32, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=64, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=64, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=64, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=32, kernel_size=(1, 1), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=10, kernel_size=(1, 1), input_quantizer=\"ste_sign\", activation='softmax', **kwargs))\n",
        "model.add(Flatten())\n",
        "\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=adam,\n",
        "       loss='categorical_crossentropy',\n",
        "       metrics=['accuracy'])\n",
        "# 定義學習率調整函數\n",
        "def lr_scheduler(epoch, learning_rate):\n",
        "    if epoch > 0 and epoch % 20 ==0:\n",
        "        return learning_rate * 0.5\n",
        "    else:\n",
        "        return learning_rate\n",
        "\n",
        "# 創建學習率調度器\n",
        "lr_callback = LearningRateScheduler(lr_scheduler)\n",
        "# 早停機制\n",
        "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
        "                  patience=15, mode='auto')\n",
        "# 斷點續訓\n",
        "checkpoint_callback = ModelCheckpoint('checkpoint.ckpt', monitor='val_accuracy',\n",
        "                    save_weights_only=True, verbose=1,\n",
        "                    save_best_only=True, mode='auto')\n",
        "'''\n",
        "if os.path.exists('checkpoint'):\n",
        "    model.load_weights('checkpoint.ckpt')\n",
        "    print(\"Cotinue with checkpoint\")\n",
        "else:\n",
        "    print(\"No checkpoint\")\n",
        "'''\n",
        "print('Training ---------------------------------')\n",
        "history = model.fit(train_dataset,\n",
        "           epochs=100,\n",
        "           batch_size=128,\n",
        "           validation_data=val_dataset,\n",
        "           callbacks=[lr_callback,\n",
        "                earlystop_callback,\n",
        "                checkpoint_callback])\n",
        "model.save('model.h5')\n",
        "\n",
        "# 繪製圖表\n",
        "plt.figure()\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc= history.history['val_accuracy']\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('model loss')\n",
        "plt.plot(loss, label='loss')\n",
        "plt.plot(val_loss, label='val_loss')\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss',\n",
        "      'valid_loss'],\n",
        "      loc='upper right')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title('model accuracy')\n",
        "plt.plot(acc, label='acc')\n",
        "plt.plot(val_acc, label='val_acc')\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy',\n",
        "      'valid_accuracy'],\n",
        "      loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('./result.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJonTWHh9tiO",
        "outputId": "3721fb32-e23e-4f2f-8821-aadf8bf979f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 10 classes.\n",
            "\n",
            "Testing ------------\n",
            "4/4 [==============================] - 2s 230ms/step - loss: 0.0994 - accuracy: 0.9750\n",
            "\n",
            "test loss:  0.09938722848892212\n",
            "\n",
            "test accuracy:  0.9750000238418579\n",
            "1/1 [==============================] - 0s 403ms/step\n",
            "1\n",
            "correct\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2\n",
            "correct\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3\n",
            "correct\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4\n",
            "correct\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5\n",
            "correct\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6\n",
            "correct\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7\n",
            "correct\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8\n",
            "correct\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9\n",
            "correct\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "10\n",
            "correct\n",
            "10\n",
            "4/4 [==============================] - 1s 244ms/step\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from pretty_confusion_matrix import pp_matrix_from_data\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test = ImageDataGenerator(rescale=1/255)\n",
        "test_dataset = test.flow_from_directory('/content/dataset/test/',\n",
        "                     target_size=(94,94),\n",
        "                     batch_size=256,\n",
        "                     color_mode='grayscale',\n",
        "                     class_mode='categorical',\n",
        "                     shuffle=False)\n",
        "\n",
        "model = load_model('model.h5')\n",
        "print('\\nTesting ------------')\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('\\ntest loss: ', loss)\n",
        "print('\\ntest accuracy: ', accuracy)\n",
        "\n",
        "j=1\n",
        "k=0\n",
        "for i in 'down','left','ok','paper','right','rock','scissors','stone','thumb','up':\n",
        "    x = cv2.imread('/content/dataset/test/{}/{}.jpg'.format(i,j))\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
        "    x = x/255\n",
        "    x = cv2.resize(x, (94, 94))\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    pred = model.predict(x)\n",
        "    #print(pred)\n",
        "    print(np.argmax(pred)+1)\n",
        "    if np.argmax(pred)+1 == j:\n",
        "      print('correct')\n",
        "      k+=1\n",
        "    else:\n",
        "      print('false')\n",
        "    j+=1\n",
        "print(k)\n",
        "\n",
        "\n",
        "# 預測測試資料\n",
        "Y_pred = model.predict(test_dataset)\n",
        "# 將預測結果轉成類別編號\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "# 取得真實類別編號\n",
        "y_true = test_dataset.classes\n",
        "# 繪製混淆矩陣\n",
        "class_name = ['down',\n",
        "        'left',\n",
        "        'ok',\n",
        "        'paper',\n",
        "        'right',\n",
        "        'rock',\n",
        "        'scissors',\n",
        "        'stone',\n",
        "        'thumb',\n",
        "        'up']\n",
        "cmap = 'terrain'\n",
        "pp_matrix_from_data(y_true, y_pred, cmap=cmap, columns=class_name)\n",
        "plt.savefig('./confusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXOBrYx49y2m",
        "outputId": "e6615770-c429-4b89-bfc8-4624960f80de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quant_conv2d\n",
            "(3, 3, 1, 16)\n",
            "quant_conv2d_1\n",
            "(3, 3, 16, 32)\n",
            "quant_conv2d_2\n",
            "(3, 3, 32, 64)\n",
            "quant_conv2d_3\n",
            "(3, 3, 64, 64)\n",
            "quant_conv2d_4\n",
            "(3, 3, 64, 64)\n",
            "quant_conv2d_5\n",
            "(1, 1, 64, 32)\n",
            "quant_conv2d_6\n",
            "(1, 1, 32, 10)\n",
            "batch_normalization\n",
            "(16,)\n",
            "batch_normalization_1\n",
            "(32,)\n",
            "batch_normalization_2\n",
            "(64,)\n",
            "batch_normalization_3\n",
            "(64,)\n",
            "batch_normalization_4\n",
            "(64,)\n",
            "batch_normalization_5\n",
            "(32,)\n"
          ]
        }
      ],
      "source": [
        "with lq.context.quantized_scope(True):\n",
        "   model.set_weights(model.get_weights())\n",
        "\n",
        "for layer in model.layers:\n",
        "  if 'conv' in layer.name:\n",
        "    print(layer.name)\n",
        "    weight, bias = model.get_layer(layer.name).get_weights()\n",
        "    print(np.shape(weight))\n",
        "    f = open('./weight/W_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(weight)[0]):\n",
        "      for j in range(np.shape(weight)[1]):\n",
        "        for k in range(np.shape(weight)[2]):\n",
        "          for l in range(np.shape(weight)[3]):\n",
        "            f.write(str(weight[i][j][k][l])+\"\\n\")\n",
        "    f.close()\n",
        "    f = open('./weight/b_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(bias)[0]):\n",
        "      f.write(str(bias[i])+\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "for layer in model.layers:\n",
        "  if 'batch_normalization' in layer.name:\n",
        "    print(layer.name)\n",
        "    a = model.get_layer(layer.name).get_weights()\n",
        "    weight = a[0]/pow(a[3]+0.001, 0.5)\n",
        "    bias = -(a[0]*a[2])/pow(a[3]+0.001, 0.5) + a[1]\n",
        "    print(np.shape(weight))\n",
        "    f = open('./weight/W_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(weight)[0]):\n",
        "      f.write(str(weight[i])+\"\\n\")\n",
        "    f.close()\n",
        "    f = open('./weight/b_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(bias)[0]):\n",
        "      f.write(str(bias[i])+\"\\n\")\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok-IquKC9zVq",
        "outputId": "11cd80a1-88df-40e2-cda9-e92e98398ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quant_conv2d (3, 3, 1, 16) (16,)\n",
            "quant_conv2d_1 (3, 3, 16, 32) (32,)\n",
            "quant_conv2d_2 (3, 3, 32, 64) (64,)\n",
            "quant_conv2d_3 (3, 3, 64, 64) (64,)\n",
            "quant_conv2d_4 (3, 3, 64, 64) (64,)\n",
            "quant_conv2d_5 (1, 1, 64, 32) (32,)\n",
            "quant_conv2d_6 (1, 1, 32, 10) (10,)\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "  if 'conv' in layer.name:\n",
        "    weight, bias = model.get_layer(layer.name).get_weights()\n",
        "    print(layer.name, weight.shape, bias.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuZC8Rn69zeu",
        "outputId": "f2b7cc7c-b73d-42df-c940-d675a1e1cb2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quant_conv2d (QuantConv2D)  (None, 92, 92, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 46, 46, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 46, 46, 16)        64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantConv2  (None, 44, 44, 32)        4640      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 22, 22, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 22, 22, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantConv2  (None, 20, 20, 64)        18496     \n",
            " D)                                                              \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 10, 10, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 10, 10, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantConv2  (None, 8, 8, 64)          36928     \n",
            " D)                                                              \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 4, 4, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantConv2  (None, 2, 2, 64)          36928     \n",
            " D)                                                              \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 1, 1, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 1, 1, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantConv2  (None, 1, 1, 32)          2080      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 1, 1, 32)          128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " quant_conv2d_6 (QuantConv2  (None, 1, 1, 10)          330       \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100650 (393.16 KB)\n",
            "Trainable params: 100106 (391.04 KB)\n",
            "Non-trainable params: 544 (2.12 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNpAlvahIKlU",
        "outputId": "edde5272-c0d3-470c-fb96-db6c278a7e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 112ms/step\n",
            "[[[[ 1.8907471  -0.63083786  0.57249606 ... -1.8391258   1.8481421\n",
            "    -3.0651014 ]\n",
            "   [ 1.8814781  -0.6447635   0.61004615 ... -1.9223722   1.8997114\n",
            "    -3.0990105 ]\n",
            "   [ 1.8612368  -0.6475956   0.56575626 ... -1.841873    1.8192127\n",
            "    -3.123893  ]\n",
            "   ...\n",
            "   [ 1.9866748  -0.661149    0.62287825 ... -1.9642822   1.949538\n",
            "    -3.256819  ]\n",
            "   [ 1.9833735  -0.6723746   0.599552   ... -1.969585    1.933385\n",
            "    -3.277365  ]\n",
            "   [ 2.0170527  -0.6964586   0.6212542  ... -1.9650124   1.9778283\n",
            "    -3.2726817 ]]\n",
            "\n",
            "  [[ 1.8894446  -0.65010613  0.61160564 ... -1.8744434   1.836853\n",
            "    -3.1475296 ]\n",
            "   [ 1.858901   -0.6743751   0.5842354  ... -1.805817    1.8204107\n",
            "    -3.1072593 ]\n",
            "   [ 1.8801234  -0.6174872   0.57951057 ... -1.8265129   1.8172901\n",
            "    -3.0786185 ]\n",
            "   ...\n",
            "   [ 1.983644   -0.66658163  0.6105025  ... -1.9592508   1.9515553\n",
            "    -3.264004  ]\n",
            "   [ 1.990148   -0.67151636  0.6118298  ... -1.9676757   1.9741397\n",
            "    -3.2881107 ]\n",
            "   [ 2.004217   -0.6871273   0.6169745  ... -1.9832093   1.9808464\n",
            "    -3.3267248 ]]\n",
            "\n",
            "  [[ 1.8508103  -0.5990975   0.5657887  ... -1.8506798   1.8388798\n",
            "    -3.0702734 ]\n",
            "   [ 1.8837984  -0.6117223   0.5877061  ... -1.8456496   1.8711495\n",
            "    -3.0329056 ]\n",
            "   [ 1.8817031  -0.60490215  0.5884132  ... -1.8734205   1.8568025\n",
            "    -3.0760815 ]\n",
            "   ...\n",
            "   [ 2.0015535  -0.68599504  0.61340314 ... -1.983389    1.958926\n",
            "    -3.298019  ]\n",
            "   [ 2.0053694  -0.6925849   0.6210199  ... -1.9982675   1.9723186\n",
            "    -3.3298104 ]\n",
            "   [ 1.9982893  -0.67594296  0.6083769  ... -1.9950219   1.9804828\n",
            "    -3.3340697 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 2.8108413  -1.531129    1.3692216  ... -2.5418253   1.5880659\n",
            "    -4.0197625 ]\n",
            "   [ 1.7867639  -1.4998608   0.3393469  ... -1.5945154   1.3796027\n",
            "    -4.036366  ]\n",
            "   [ 2.0544426  -0.86881846  0.71045977 ... -1.9587822   1.9382576\n",
            "    -3.3726814 ]\n",
            "   ...\n",
            "   [ 1.9396303  -0.6405646   0.59141254 ... -1.9040829   1.9011068\n",
            "    -3.210806  ]\n",
            "   [ 1.9592956  -0.62714     0.62442094 ... -1.9285116   1.9451293\n",
            "    -3.1723297 ]\n",
            "   [ 1.9521164  -0.6317532   0.60021335 ... -1.9305956   1.9448372\n",
            "    -3.2081006 ]]\n",
            "\n",
            "  [[ 2.2147014  -0.7859853   0.757705   ... -2.1027734   2.1954036\n",
            "    -3.4891648 ]\n",
            "   [ 2.2648292  -0.8119065   0.82360244 ... -2.0942633   2.1536636\n",
            "    -3.4677804 ]\n",
            "   [ 2.2601614  -0.9151378   0.809951   ... -2.104657    2.0198686\n",
            "    -3.446246  ]\n",
            "   ...\n",
            "   [ 1.9781449  -0.6481586   0.6310884  ... -1.9581794   1.9712322\n",
            "    -3.204804  ]\n",
            "   [ 1.994567   -0.6908912   0.6289535  ... -1.96891     1.9417833\n",
            "    -3.2306893 ]\n",
            "   [ 1.9690477  -0.6771561   0.6005724  ... -1.9584217   1.9082785\n",
            "    -3.2676609 ]]\n",
            "\n",
            "  [[ 2.1597247  -0.7286974   0.69743365 ... -2.0858958   2.1171017\n",
            "    -3.5023997 ]\n",
            "   [ 2.1880333  -0.75147057  0.71085835 ... -2.1106067   2.0689688\n",
            "    -3.5152004 ]\n",
            "   [ 2.1959398  -0.79577005  0.72753125 ... -2.0570018   2.1423454\n",
            "    -3.4650495 ]\n",
            "   ...\n",
            "   [ 1.9557598  -0.66982657  0.60882473 ... -1.9221281   1.9037099\n",
            "    -3.240187  ]\n",
            "   [ 1.9559997  -0.66787964  0.5925246  ... -1.8991183   1.9147074\n",
            "    -3.2434537 ]\n",
            "   [ 1.9777877  -0.6710202   0.6240295  ... -1.9567097   1.9545062\n",
            "    -3.2664845 ]]]]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import larq as lq\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "model = load_model('model.h5')\n",
        "x = cv2.imread('/content/dataset/test/down/1.jpg')\n",
        "x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
        "x = x/255\n",
        "x = cv2.resize(x, (94, 94))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "conv_model = Model(inputs=model.input, outputs=model.get_layer('quant_conv2d').output)\n",
        "conv_output = conv_model.predict(x)\n",
        "print(conv_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRDbo6AbPQh7",
        "outputId": "3e0aebed-c689-49c7-b482-f90bdab7f2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 516ms/step\n",
            "[[[[ 1.8907471  -0.63083786  0.61160564 ... -1.805817    1.8997114\n",
            "    -3.0651014 ]\n",
            "   [ 1.8801234  -0.6174872   0.57951057 ... -1.8265129   1.8711238\n",
            "    -3.0666397 ]\n",
            "   [ 1.9135083  -0.59297323  0.6110509  ... -1.8408482   1.8677378\n",
            "    -3.0844448 ]\n",
            "   ...\n",
            "   [ 2.0189285  -0.67019874  0.6615631  ... -1.9483994   2.0006843\n",
            "    -3.258609  ]\n",
            "   [ 1.9866748  -0.661149    0.62287825 ... -1.9306251   1.9572618\n",
            "    -3.2498574 ]\n",
            "   [ 2.0170527  -0.67151636  0.6212542  ... -1.9650124   1.9808464\n",
            "    -3.2726817 ]]\n",
            "\n",
            "  [[ 1.890965   -0.5990975   0.5975708  ... -1.8456496   1.8711495\n",
            "    -3.0329056 ]\n",
            "   [ 1.8847841  -0.60490215  0.5979783  ... -1.8399743   1.8788111\n",
            "    -3.0760815 ]\n",
            "   [ 1.8926609  -0.60498285  0.6168919  ... -1.819249    1.8958147\n",
            "    -3.0692992 ]\n",
            "   ...\n",
            "   [ 2.0113807  -0.64245874  0.6354794  ... -1.9318477   2.0088606\n",
            "    -3.2305903 ]\n",
            "   [ 2.0015535  -0.65165526  0.61340314 ... -1.9387602   1.989221\n",
            "    -3.2651298 ]\n",
            "   [ 2.0135775  -0.67594296  0.62550074 ... -1.9790454   1.9804828\n",
            "    -3.3268836 ]]\n",
            "\n",
            "  [[ 1.9007561  -0.6056917   0.6034772  ... -1.8378986   1.8896599\n",
            "    -3.0709236 ]\n",
            "   [ 1.9015334  -0.62174195  0.5935973  ... -1.8365749   1.9053423\n",
            "    -3.0829008 ]\n",
            "   [ 1.9108942  -0.63978887  0.6164367  ... -1.8540367   1.8942082\n",
            "    -3.0896492 ]\n",
            "   ...\n",
            "   [ 2.0344017  -0.67451215  0.66276205 ... -1.9589299   2.0045242\n",
            "    -3.2783608 ]\n",
            "   [ 2.0015001  -0.6579331   0.63334113 ... -1.9660596   1.98595\n",
            "    -3.293143  ]\n",
            "   [ 2.0044646  -0.6402855   0.6294009  ... -1.9718583   2.007232\n",
            "    -3.2742894 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.0863156   0.20073527 -0.14075859 ... -0.5782629   0.60671806\n",
            "    -0.84519494]\n",
            "   [ 1.9851253  -0.3093176   0.6765361  ... -1.5767869   1.931902\n",
            "    -2.838899  ]\n",
            "   [ 1.9412217  -0.6230489   0.64575565 ... -1.8678149   1.9196563\n",
            "    -3.120185  ]\n",
            "   ...\n",
            "   [ 2.0094776  -0.6314721   0.6678445  ... -1.9451755   1.9686332\n",
            "    -3.2353632 ]\n",
            "   [ 1.9852709  -0.62780476  0.6024559  ... -1.9352096   1.9927405\n",
            "    -3.241884  ]\n",
            "   [ 2.0343337  -0.6628128   0.6871865  ... -1.9358499   1.9975147\n",
            "    -3.2389727 ]]\n",
            "\n",
            "  [[ 2.8108413  -1.0299144   1.3692216  ... -1.3685703   1.6790507\n",
            "    -3.5334105 ]\n",
            "   [ 2.0544426  -0.6612663   0.71045977 ... -1.7162724   1.9564333\n",
            "    -3.1573331 ]\n",
            "   [ 1.9396696  -0.61568654  0.6270859  ... -1.8506824   1.8996065\n",
            "    -3.090095  ]\n",
            "   ...\n",
            "   [ 2.0254166  -0.6244944   0.680518   ... -1.909189    1.9830874\n",
            "    -3.2115324 ]\n",
            "   [ 1.9462664  -0.6327929   0.60881543 ... -1.9040829   1.9738076\n",
            "    -3.210806  ]\n",
            "   [ 1.9793756  -0.62714     0.6345523  ... -1.9120069   1.9582111\n",
            "    -3.1723297 ]]\n",
            "\n",
            "  [[ 2.2648292  -0.7286974   0.82360244 ... -2.0858958   2.1954036\n",
            "    -3.4677804 ]\n",
            "   [ 2.2847326  -0.79577005  0.83729875 ... -2.00515     2.1423454\n",
            "    -3.3750749 ]\n",
            "   [ 2.2357953  -0.7447693   0.75277066 ... -1.9551787   1.9798119\n",
            "    -3.216191  ]\n",
            "   ...\n",
            "   [ 1.977525   -0.35142726  0.63631564 ... -1.8395989   1.9405476\n",
            "    -2.9228952 ]\n",
            "   [ 1.9781449  -0.6481586   0.6399492  ... -1.9041992   1.9712322\n",
            "    -3.204804  ]\n",
            "   [ 1.994567   -0.66787964  0.6289535  ... -1.8991183   1.9545062\n",
            "    -3.2306893 ]]]]\n"
          ]
        }
      ],
      "source": [
        "pool_model = Model(inputs=model.input, outputs=model.get_layer('max_pooling2d').output)\n",
        "pool_output = pool_model.predict(x)\n",
        "print(pool_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFpNaQFBmosk",
        "outputId": "71a657d3-212b-4f97-bdf3-65245f863dff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a577007c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 539ms/step\n",
            "[[[[ 0.29873782 -0.7511627   0.14810602 ... -0.2458733   0.7354265\n",
            "    -0.547823  ]\n",
            "   [ 0.28033894 -0.70645255  0.03431716 ... -0.28026688  0.67822516\n",
            "    -0.54924655]\n",
            "   [ 0.3381573  -0.6243575   0.14613926 ... -0.30409     0.67144996\n",
            "    -0.5657241 ]\n",
            "   ...\n",
            "   [ 0.5207314  -0.8829787   0.3252236  ... -0.4828244   0.9374647\n",
            "    -0.726902  ]\n",
            "   [ 0.4648721  -0.85267204  0.18807156 ... -0.45328602  0.85058004\n",
            "    -0.7188029 ]\n",
            "   [ 0.51748264 -0.88739127  0.18231373 ... -0.5104328   0.89777076\n",
            "    -0.7399254 ]]\n",
            "\n",
            "  [[ 0.2991152  -0.6448671   0.09834725 ... -0.31206924  0.67827666\n",
            "    -0.51802784]\n",
            "   [ 0.28841072 -0.6643064   0.09979204 ... -0.30263767  0.69360685\n",
            "    -0.5579844 ]\n",
            "   [ 0.30205226 -0.66457665  0.16684781 ... -0.26819533  0.7276295\n",
            "    -0.5517078 ]\n",
            "   ...\n",
            "   [ 0.50765944 -0.79007995  0.23274724 ... -0.45531783  0.9538248\n",
            "    -0.7009725 ]\n",
            "   [ 0.49064013 -0.82087827  0.1544788  ... -0.46680534  0.91452765\n",
            "    -0.7329365 ]\n",
            "   [ 0.511464   -0.90221554  0.19736925 ... -0.53375345  0.89704335\n",
            "    -0.79008573]]\n",
            "\n",
            "  [[ 0.31607217 -0.6669504   0.11928762 ... -0.29918826  0.71531427\n",
            "    -0.5532111 ]\n",
            "   [ 0.31741828 -0.72070134  0.08425978 ... -0.29698846  0.74669355\n",
            "    -0.56429523]\n",
            "   [ 0.33362994 -0.7811388   0.16523395 ... -0.3260073   0.72441506\n",
            "    -0.5705404 ]\n",
            "   ...\n",
            "   [ 0.5475288  -0.89742386  0.3294743  ... -0.5003245   0.94514817\n",
            "    -0.745181  ]\n",
            "   [ 0.49054766 -0.8419022   0.22516632 ... -0.51217294  0.9079827\n",
            "    -0.758861  ]\n",
            "   [ 0.4956818  -0.7828019   0.21119678 ... -0.5218095   0.950566\n",
            "    -0.7414131 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.0944325   2.0336998  -2.5193021  ...  1.7941418  -1.8517439\n",
            "     1.5065589 ]\n",
            "   [ 0.4621886   0.3255793   0.37830833 ...  0.13474123  0.7998373\n",
            "    -0.33848703]\n",
            "   [ 0.3861533  -0.7250782   0.26918036 ... -0.3489047   0.77533454\n",
            "    -0.5987993 ]\n",
            "   ...\n",
            "   [ 0.5043636  -0.7532867   0.34749338 ... -0.47746673  0.8733332\n",
            "    -0.7053895 ]\n",
            "   [ 0.46244067 -0.7410051   0.11566686 ... -0.4609049   0.9215699\n",
            "    -0.711424  ]\n",
            "   [ 0.54741114 -0.85824394  0.4160679  ... -0.46196893  0.93112266\n",
            "    -0.70872974]]\n",
            "\n",
            "  [[ 1.8922211  -2.0876336   2.8341334  ...  0.48076665  0.29390305\n",
            "    -0.9812133 ]\n",
            "   [ 0.5822372  -0.8530649   0.49858028 ... -0.09706321  0.84892225\n",
            "    -0.6331776 ]\n",
            "   [ 0.38346526 -0.7004223   0.20298931 ... -0.32043293  0.73521656\n",
            "    -0.5709531 ]\n",
            "   ...\n",
            "   [ 0.5319679  -0.72991896  0.3924256  ... -0.41766238  0.9022549\n",
            "    -0.6833355 ]\n",
            "   [ 0.39489007 -0.7577099   0.1382137  ... -0.4091768   0.88368666\n",
            "    -0.6826632 ]\n",
            "   [ 0.45223087 -0.7387788   0.22946036 ... -0.42234528  0.8524794\n",
            "    -0.6470559 ]]\n",
            "\n",
            "  [[ 0.9465991  -1.0788854   0.89971274 ... -0.7113232   1.3270816\n",
            "    -0.92047673]\n",
            "   [ 0.9810693  -1.3035054   0.94827116 ... -0.5771356   1.2209166\n",
            "    -0.8346837 ]\n",
            "   [ 0.89631623 -1.1327085   0.64858794 ... -0.49409062  0.8957009\n",
            "    -0.68764687]\n",
            "   ...\n",
            "   [ 0.44902587  0.18455787  0.23571207 ... -0.30201384  0.8171363\n",
            "    -0.41622022]\n",
            "   [ 0.45009944 -0.80916834  0.24859437 ... -0.40937018  0.87853354\n",
            "    -0.6771088 ]\n",
            "   [ 0.47854045 -0.87521225  0.20961061 ... -0.40092638  0.8450662\n",
            "    -0.70106405]]]]\n"
          ]
        }
      ],
      "source": [
        "bn_model = Model(inputs=model.input, outputs=model.get_layer('batch_normalization').output)\n",
        "bn_output = bn_model.predict(x)\n",
        "print(bn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEb2O_otQov1",
        "outputId": "38b8e2a6-15b2-470a-fff3-296e01d9cf59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.7318696  3.3489084  3.5453682  1.3990011  4.540227   3.2058363\n",
            " 3.0234506  1.1260498  4.230028   1.6504177  2.6673472  1.5945413\n",
            " 0.97769845 1.6618536  2.0009155  0.9254362 ]\n",
            "[-2.9757895   1.3614556  -2.020261    1.8797262  -2.7428293   1.5841062\n",
            "  1.3130219  -3.3995714  -2.5005271   2.459118   -1.5865941   2.2283335\n",
            "  0.79317385  2.75513    -3.0657353   2.2887325 ]\n"
          ]
        }
      ],
      "source": [
        "a = model.get_layer('batch_normalization').get_weights()\n",
        "weight = a[0]/pow(a[3]+0.001, 0.5)\n",
        "bias = -(a[0]*a[2])/pow(a[3]+0.001, 0.5) + a[1]\n",
        "print(weight)\n",
        "print(bias)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
