{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bojunchen3/Project/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ-pZvQa6W8-",
        "outputId": "a15b19e6-704a-4422-9d30-c0161a155e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install larq\n",
        "!pip uninstall sklearn\n",
        "!pip install pretty_confusion_matrix\n",
        "%mkdir dataset\n",
        "%cd /content/drive/MyDrive/project\n",
        "!unrar x /content/drive/MyDrive/project/dataset.rar -d /content/dataset"
      ],
      "metadata": {
        "id": "oOvUjGal71zA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af6a3c1-aba6-400f-d732-e8a7ac420404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: larq in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from larq) (1.23.5)\n",
            "Requirement already satisfied: terminaltables>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from larq) (3.1.10)\n",
            "Requirement already satisfied: packaging>=19.2 in /usr/local/lib/python3.10/dist-packages (from larq) (23.1)\n",
            "\u001b[33mWARNING: Skipping sklearn as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pretty_confusion_matrix\n",
            "  Using cached pretty_confusion_matrix-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Collecting black<22.0,>=21.5b0 (from pretty_confusion_matrix)\n",
            "  Using cached black-21.12b0-py3-none-any.whl (156 kB)\n",
            "Collecting flake8<4.0.0,>=3.9.2 (from pretty_confusion_matrix)\n",
            "  Using cached flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n",
            "Collecting isort<6.0.0,>=5.8.0 (from pretty_confusion_matrix)\n",
            "  Using cached isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from pretty_confusion_matrix) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from pretty_confusion_matrix) (1.23.5)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from pretty_confusion_matrix) (1.5.3)\n",
            "Collecting pre-commit<3.0.0,>=2.12.1 (from pretty_confusion_matrix)\n",
            "  Using cached pre_commit-2.21.0-py2.py3-none-any.whl (201 kB)\n",
            "Collecting seaborn<0.12.0,>=0.11.2 (from pretty_confusion_matrix)\n",
            "  Using cached seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
            "Collecting sklearn<0.1,>=0.0 (from pretty_confusion_matrix)\n",
            "  Using cached sklearn-0.0.post7.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from black<22.0,>=21.5b0->pretty_confusion_matrix) (8.1.7)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black<22.0,>=21.5b0->pretty_confusion_matrix) (3.10.0)\n",
            "Collecting tomli<2.0.0,>=0.2.6 (from black<22.0,>=21.5b0->pretty_confusion_matrix)\n",
            "  Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\n",
            "Collecting pathspec<1,>=0.9.0 (from black<22.0,>=21.5b0->pretty_confusion_matrix)\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from black<22.0,>=21.5b0->pretty_confusion_matrix) (4.7.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black<22.0,>=21.5b0->pretty_confusion_matrix)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pyflakes<2.4.0,>=2.3.0 (from flake8<4.0.0,>=3.9.2->pretty_confusion_matrix)\n",
            "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0 (from flake8<4.0.0,>=3.9.2->pretty_confusion_matrix)\n",
            "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0 (from flake8<4.0.0,>=3.9.2->pretty_confusion_matrix)\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.4->pretty_confusion_matrix) (2023.3)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix)\n",
            "  Downloading identify-2.5.27-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix) (6.0.1)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix)\n",
            "  Downloading virtualenv-20.24.3-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from seaborn<0.12.0,>=0.11.2->pretty_confusion_matrix) (1.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.5.0->pretty_confusion_matrix) (1.16.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix)\n",
            "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit<3.0.0,>=2.12.1->pretty_confusion_matrix) (3.12.2)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post7-py3-none-any.whl size=2951 sha256=782f588aea3fcbea614f731684aa6f140b6fb41b5c23aac4b4dabc3ece8d8507\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/9c/85/72901eb50bc4bc6e3b2629378d172384ea3dfd19759c77fd2c\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn, mccabe, distlib, virtualenv, tomli, pyflakes, pycodestyle, pathspec, nodeenv, mypy-extensions, isort, identify, cfgv, pre-commit, flake8, black, seaborn, pretty_confusion_matrix\n",
            "  Attempting uninstall: tomli\n",
            "    Found existing installation: tomli 2.0.1\n",
            "    Uninstalling tomli-2.0.1:\n",
            "      Successfully uninstalled tomli-2.0.1\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.12.2\n",
            "    Uninstalling seaborn-0.12.2:\n",
            "      Successfully uninstalled seaborn-0.12.2\n",
            "Successfully installed black-21.12b0 cfgv-3.4.0 distlib-0.3.7 flake8-3.9.2 identify-2.5.27 isort-5.12.0 mccabe-0.6.1 mypy-extensions-1.0.0 nodeenv-1.8.0 pathspec-0.11.2 pre-commit-2.21.0 pretty_confusion_matrix-0.1.1 pycodestyle-2.7.0 pyflakes-2.3.1 seaborn-0.11.2 sklearn-0.0.post7 tomli-1.2.3 virtualenv-20.24.3\n",
            "/content/drive/MyDrive/project\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/project/dataset.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/dataset/train/down/1.jpg\n",
            " 21533 bytes, modified on 2023-06-28 07:47\n",
            "with a new one\n",
            " 21533 bytes, modified on 2023-06-28 07:47\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit \n",
            "User break\n",
            "\n",
            "User break\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.layers import Softmax, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model, Sequential\n",
        "from larq.layers import QuantConv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "# 導入資料集\n",
        "train = ImageDataGenerator(rescale=1/255)\n",
        "val = ImageDataGenerator(rescale=1/255)\n",
        "train_dataset = train.flow_from_directory('/content/dataset/train/',\n",
        "                      target_size=(46,46),\n",
        "                      batch_size=128,\n",
        "                      color_mode='grayscale',\n",
        "                      class_mode='categorical')\n",
        "val_dataset = val.flow_from_directory('/content/dataset/validation/',\n",
        "                    target_size=(46,46),\n",
        "                    batch_size=128,\n",
        "                    color_mode='grayscale',\n",
        "                    class_mode='categorical')\n",
        "kwargs = dict(kernel_quantizer=\"ste_sign\",\n",
        "        kernel_constraint=\"weight_clip\")\n",
        "# 定義模型架構\n",
        "model = Sequential()\n",
        "model.add(QuantConv2D(filters=8, kernel_size=(3, 3), input_shape=(46, 46, 1), **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=16, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=32, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=32, kernel_size=(3, 3), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=32, kernel_size=(1, 1), input_quantizer=\"ste_sign\", **kwargs))\n",
        "model.add(BatchNormalization(momentum=0.9))\n",
        "model.add(QuantConv2D(filters=10, kernel_size=(1, 1), input_quantizer=\"ste_sign\", activation='softmax', **kwargs))\n",
        "model.add(Flatten())\n",
        "\n",
        "adam = Adam(learning_rate=0.005)\n",
        "model.compile(optimizer=adam,\n",
        "       loss='categorical_crossentropy',\n",
        "       metrics=['accuracy'])\n",
        "# 定義學習率調整函數\n",
        "def lr_scheduler(epoch, learning_rate):\n",
        "    if epoch > 0 and epoch % 20 ==0:\n",
        "        return learning_rate * 0.5\n",
        "    else:\n",
        "        return learning_rate\n",
        "\n",
        "# 創建學習率調度器\n",
        "lr_callback = LearningRateScheduler(lr_scheduler)\n",
        "# 早停機制\n",
        "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
        "                  patience=10, mode='auto')\n",
        "# 斷點續訓\n",
        "checkpoint_callback = ModelCheckpoint('checkpoint.ckpt', monitor='val_accuracy',\n",
        "                    save_weights_only=True, verbose=1,\n",
        "                    save_best_only=True, mode='auto')\n",
        "'''\n",
        "if os.path.exists('checkpoint'):\n",
        "    model.load_weights('checkpoint.ckpt')\n",
        "    print(\"Cotinue with checkpoint\")\n",
        "else:\n",
        "    print(\"No checkpoint\")\n",
        "'''\n",
        "print('Training ---------------------------------')\n",
        "history = model.fit(train_dataset,\n",
        "           epochs=100,\n",
        "           batch_size=128,\n",
        "           validation_data=val_dataset,\n",
        "           callbacks=[lr_callback,\n",
        "                earlystop_callback,\n",
        "                checkpoint_callback])\n",
        "model.save('model.h5')\n",
        "\n",
        "# 繪製圖表\n",
        "plt.figure()\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc= history.history['val_accuracy']\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('model loss')\n",
        "plt.plot(loss, label='loss')\n",
        "plt.plot(val_loss, label='val_loss')\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss',\n",
        "      'valid_loss'],\n",
        "      loc='upper right')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title('model accuracy')\n",
        "plt.plot(acc, label='acc')\n",
        "plt.plot(val_acc, label='val_acc')\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy',\n",
        "      'valid_accuracy'],\n",
        "      loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('./result.png')\n"
      ],
      "metadata": {
        "id": "XcYpqMY36fBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baad23f2-0574-4fa2-e955-12e175b27d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 10 classes.\n",
            "Found 1000 images belonging to 10 classes.\n",
            "Training ---------------------------------\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 3.2624 - accuracy: 0.4674\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55100, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 25s 196ms/step - loss: 3.2624 - accuracy: 0.4674 - val_loss: 2.4744 - val_accuracy: 0.5510 - lr: 0.0050\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.1231 - accuracy: 0.7338\n",
            "Epoch 2: val_accuracy improved from 0.55100 to 0.60400, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 1.1231 - accuracy: 0.7338 - val_loss: 2.3379 - val_accuracy: 0.6040 - lr: 0.0050\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7236 - accuracy: 0.8298\n",
            "Epoch 3: val_accuracy improved from 0.60400 to 0.69600, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 7s 174ms/step - loss: 0.7236 - accuracy: 0.8298 - val_loss: 1.5094 - val_accuracy: 0.6960 - lr: 0.0050\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.8340\n",
            "Epoch 4: val_accuracy improved from 0.69600 to 0.79000, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 6s 143ms/step - loss: 0.6401 - accuracy: 0.8340 - val_loss: 1.2747 - val_accuracy: 0.7900 - lr: 0.0050\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.9130\n",
            "Epoch 5: val_accuracy did not improve from 0.79000\n",
            "40/40 [==============================] - 7s 168ms/step - loss: 0.3188 - accuracy: 0.9130 - val_loss: 1.3087 - val_accuracy: 0.7600 - lr: 0.0050\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9210\n",
            "Epoch 6: val_accuracy did not improve from 0.79000\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.3239 - accuracy: 0.9210 - val_loss: 1.8970 - val_accuracy: 0.6940 - lr: 0.0050\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.8874\n",
            "Epoch 7: val_accuracy improved from 0.79000 to 0.80500, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 8s 202ms/step - loss: 0.4795 - accuracy: 0.8874 - val_loss: 1.2466 - val_accuracy: 0.8050 - lr: 0.0050\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9406\n",
            "Epoch 8: val_accuracy improved from 0.80500 to 0.84200, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.2334 - accuracy: 0.9406 - val_loss: 0.9352 - val_accuracy: 0.8420 - lr: 0.0050\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9376\n",
            "Epoch 9: val_accuracy did not improve from 0.84200\n",
            "40/40 [==============================] - 7s 169ms/step - loss: 0.2418 - accuracy: 0.9376 - val_loss: 2.9896 - val_accuracy: 0.5840 - lr: 0.0050\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9618\n",
            "Epoch 10: val_accuracy did not improve from 0.84200\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.1522 - accuracy: 0.9618 - val_loss: 2.0374 - val_accuracy: 0.7190 - lr: 0.0050\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9460\n",
            "Epoch 11: val_accuracy improved from 0.84200 to 0.86500, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 7s 173ms/step - loss: 0.2235 - accuracy: 0.9460 - val_loss: 0.7848 - val_accuracy: 0.8650 - lr: 0.0050\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9622\n",
            "Epoch 12: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 145ms/step - loss: 0.1387 - accuracy: 0.9622 - val_loss: 1.2888 - val_accuracy: 0.7900 - lr: 0.0050\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9554\n",
            "Epoch 13: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.1596 - accuracy: 0.9554 - val_loss: 1.2979 - val_accuracy: 0.7920 - lr: 0.0050\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9502\n",
            "Epoch 14: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 7s 172ms/step - loss: 0.1995 - accuracy: 0.9502 - val_loss: 2.0484 - val_accuracy: 0.7010 - lr: 0.0050\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.9160\n",
            "Epoch 15: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.3842 - accuracy: 0.9160 - val_loss: 1.2533 - val_accuracy: 0.7910 - lr: 0.0050\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9612\n",
            "Epoch 16: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 7s 174ms/step - loss: 0.1555 - accuracy: 0.9612 - val_loss: 1.4778 - val_accuracy: 0.8190 - lr: 0.0050\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9462\n",
            "Epoch 17: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 6s 140ms/step - loss: 0.2066 - accuracy: 0.9462 - val_loss: 1.2154 - val_accuracy: 0.8390 - lr: 0.0050\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9732\n",
            "Epoch 18: val_accuracy did not improve from 0.86500\n",
            "40/40 [==============================] - 8s 194ms/step - loss: 0.0928 - accuracy: 0.9732 - val_loss: 1.1999 - val_accuracy: 0.8510 - lr: 0.0050\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9804\n",
            "Epoch 19: val_accuracy improved from 0.86500 to 0.86600, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 0.0831 - accuracy: 0.9804 - val_loss: 1.0521 - val_accuracy: 0.8660 - lr: 0.0050\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9802\n",
            "Epoch 20: val_accuracy did not improve from 0.86600\n",
            "40/40 [==============================] - 6s 158ms/step - loss: 0.0770 - accuracy: 0.9802 - val_loss: 1.1469 - val_accuracy: 0.8370 - lr: 0.0050\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9866\n",
            "Epoch 21: val_accuracy did not improve from 0.86600\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 1.2349 - val_accuracy: 0.8350 - lr: 0.0025\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9876\n",
            "Epoch 22: val_accuracy improved from 0.86600 to 0.88500, saving model to checkpoint.ckpt\n",
            "40/40 [==============================] - 6s 143ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 0.9298 - val_accuracy: 0.8850 - lr: 0.0025\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9868\n",
            "Epoch 23: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 7s 172ms/step - loss: 0.0521 - accuracy: 0.9868 - val_loss: 1.4948 - val_accuracy: 0.8230 - lr: 0.0025\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9776\n",
            "Epoch 24: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 8s 192ms/step - loss: 0.0847 - accuracy: 0.9776 - val_loss: 1.8982 - val_accuracy: 0.7520 - lr: 0.0025\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9868\n",
            "Epoch 25: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 5s 135ms/step - loss: 0.0438 - accuracy: 0.9868 - val_loss: 1.2005 - val_accuracy: 0.8290 - lr: 0.0025\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9826\n",
            "Epoch 26: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 7s 184ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.9189 - val_accuracy: 0.8670 - lr: 0.0025\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9808\n",
            "Epoch 27: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 6s 143ms/step - loss: 0.0700 - accuracy: 0.9808 - val_loss: 0.8380 - val_accuracy: 0.8840 - lr: 0.0025\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9894\n",
            "Epoch 28: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 8s 189ms/step - loss: 0.0409 - accuracy: 0.9894 - val_loss: 0.9616 - val_accuracy: 0.8680 - lr: 0.0025\n",
            "Epoch 29/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9894\n",
            "Epoch 29: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 1.1028 - val_accuracy: 0.8520 - lr: 0.0025\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9646\n",
            "Epoch 30: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.1246 - accuracy: 0.9646 - val_loss: 1.4557 - val_accuracy: 0.7990 - lr: 0.0025\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9728\n",
            "Epoch 31: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 6s 160ms/step - loss: 0.1148 - accuracy: 0.9728 - val_loss: 1.4717 - val_accuracy: 0.8040 - lr: 0.0025\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9856\n",
            "Epoch 32: val_accuracy did not improve from 0.88500\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0540 - accuracy: 0.9856 - val_loss: 1.0624 - val_accuracy: 0.8670 - lr: 0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from pretty_confusion_matrix import pp_matrix_from_data\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test = ImageDataGenerator(rescale=1/255)\n",
        "test_dataset = test.flow_from_directory('/content/dataset/test/',\n",
        "                     target_size=(46,46),\n",
        "                     batch_size=256,\n",
        "                     color_mode='grayscale',\n",
        "                     class_mode='categorical',\n",
        "                     shuffle=False)\n",
        "\n",
        "model = load_model('model.h5')\n",
        "print('\\nTesting ------------')\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('\\ntest loss: ', loss)\n",
        "print('\\ntest accuracy: ', accuracy)\n",
        "\n",
        "j=1\n",
        "k=0\n",
        "for i in 'down','left','ok','paper','right','rock','scissors','stone','thumb','up':\n",
        "    x = cv2.imread('/content/dataset/test/{}/{}.jpg'.format(i,j))\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
        "    x = x/255\n",
        "    x = cv2.resize(x, (46, 46))\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    pred = model.predict(x)\n",
        "    #print(pred)\n",
        "    print(np.argmax(pred)+1)\n",
        "    if np.argmax(pred)+1 == j:\n",
        "      print('correct')\n",
        "      k+=1\n",
        "    else:\n",
        "      print('false')\n",
        "    j+=1\n",
        "print(k)\n",
        "\n",
        "\n",
        "# 預測測試資料\n",
        "Y_pred = model.predict(test_dataset)\n",
        "# 將預測結果轉成類別編號\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "# 取得真實類別編號\n",
        "y_true = test_dataset.classes\n",
        "# 繪製混淆矩陣\n",
        "class_name = ['down',\n",
        "        'left',\n",
        "        'ok',\n",
        "        'paper',\n",
        "        'right',\n",
        "        'rock',\n",
        "        'scissors',\n",
        "        'stone',\n",
        "        'thumb',\n",
        "        'up']\n",
        "cmap = 'terrain'\n",
        "pp_matrix_from_data(y_true, y_pred, cmap=cmap, columns=class_name)\n",
        "plt.savefig('./confusion.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJonTWHh9tiO",
        "outputId": "d651b933-b0e6-496a-ae58-431f8c561aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 10 classes.\n",
            "\n",
            "Testing ------------\n",
            "4/4 [==============================] - 2s 321ms/step - loss: 0.4652 - accuracy: 0.9180\n",
            "\n",
            "test loss:  0.4651755392551422\n",
            "\n",
            "test accuracy:  0.9179999828338623\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1\n",
            "correct\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2\n",
            "correct\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3\n",
            "correct\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7\n",
            "false\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5\n",
            "correct\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "6\n",
            "correct\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7\n",
            "correct\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "8\n",
            "correct\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9\n",
            "correct\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "10\n",
            "correct\n",
            "9\n",
            "4/4 [==============================] - 4s 832ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with lq.context.quantized_scope(True):\n",
        "   model.set_weights(model.get_weights())\n",
        "\n",
        "for layer in model.layers:\n",
        "  if 'conv' in layer.name:\n",
        "    print(layer.name)\n",
        "    weight, bias = model.get_layer(layer.name).get_weights()\n",
        "    print(np.shape(weight))\n",
        "    f = open('./weight/W_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(weight)[0]):\n",
        "      for j in range(np.shape(weight)[1]):\n",
        "        for k in range(np.shape(weight)[2]):\n",
        "          for l in range(np.shape(weight)[3]):\n",
        "            f.write(str(weight[i][j][k][l])+\"\\n\")\n",
        "    f.close()\n",
        "    f = open('./weight/b_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(bias)[0]):\n",
        "      f.write(str(bias[i])+\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "for layer in model.layers:\n",
        "  if 'batch_normalization' in layer.name:\n",
        "    print(layer.name)\n",
        "    a = model.get_layer(layer.name).get_weights()\n",
        "    weight = a[0]/pow(a[3]+0.001, 0.5)\n",
        "    bias = -(a[0]*a[2])/pow(a[3]+0.001, 0.5) + a[1]\n",
        "    print(np.shape(weight))\n",
        "    f = open('./weight/W_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(weight)[0]):\n",
        "      f.write(str(weight[i])+\"\\n\")\n",
        "    f.close()\n",
        "    f = open('./weight/b_'+layer.name+'.bin', 'w')\n",
        "    for i in range(np.shape(bias)[0]):\n",
        "      f.write(str(bias[i])+\"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXOBrYx49y2m",
        "outputId": "d7249b57-fb7c-4d0e-8921-1a81d163a688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quant_conv2d\n",
            "(3, 3, 1, 8)\n",
            "quant_conv2d_1\n",
            "(3, 3, 8, 16)\n",
            "quant_conv2d_2\n",
            "(3, 3, 16, 32)\n",
            "quant_conv2d_3\n",
            "(3, 3, 32, 32)\n",
            "quant_conv2d_4\n",
            "(1, 1, 32, 32)\n",
            "quant_conv2d_5\n",
            "(1, 1, 32, 10)\n",
            "batch_normalization\n",
            "(8,)\n",
            "batch_normalization_1\n",
            "(16,)\n",
            "batch_normalization_2\n",
            "(32,)\n",
            "batch_normalization_3\n",
            "(32,)\n",
            "batch_normalization_4\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  if 'conv' in layer.name:\n",
        "    weight, bias = model.get_layer(layer.name).get_weights()\n",
        "    print(layer.name, weight.shape, bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok-IquKC9zVq",
        "outputId": "b65b3e7c-4250-41ed-9f3f-f4c9edf26cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quant_conv2d (3, 3, 1, 8) (8,)\n",
            "quant_conv2d_1 (3, 3, 8, 16) (16,)\n",
            "quant_conv2d_2 (3, 3, 16, 32) (32,)\n",
            "quant_conv2d_3 (3, 3, 32, 32) (32,)\n",
            "quant_conv2d_4 (1, 1, 32, 32) (32,)\n",
            "quant_conv2d_5 (1, 1, 32, 10) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuZC8Rn69zeu",
        "outputId": "d60f0f63-4d0f-4508-f340-c02cd52c59e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quant_conv2d (QuantConv2D)  (None, 44, 44, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 22, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 22, 22, 8)        32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantConv2D  (None, 20, 20, 16)       1168      \n",
            " )                                                               \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 10, 10, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantConv2D  (None, 8, 8, 32)         4640      \n",
            " )                                                               \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantConv2D  (None, 2, 2, 32)         9248      \n",
            " )                                                               \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 1, 1, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantConv2D  (None, 1, 1, 32)         1056      \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 1, 1, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantConv2D  (None, 1, 1, 10)         330       \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,002\n",
            "Trainable params: 16,762\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import larq as lq\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "model = load_model('model.h5')\n",
        "x = cv2.imread('/content/dataset/test/down/1.jpg')\n",
        "x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
        "x = x/255\n",
        "x = cv2.resize(x, (46, 46))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "conv_model = Model(inputs=model.input, outputs=model.get_layer('quant_conv2d').output)\n",
        "conv_output = conv_model.predict(x)\n",
        "print(conv_output)\n"
      ],
      "metadata": {
        "id": "wNpAlvahIKlU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2693071f-abba-4bdc-9303-bd99f578dbaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "[[[[-0.6325317  -1.8141849  -0.60731727 ...  1.8651901   0.55306983\n",
            "    -3.101766  ]\n",
            "   [-0.56538695 -1.8561027  -0.6433749  ...  1.8820368   0.63792825\n",
            "    -3.111837  ]\n",
            "   [-0.6739619  -1.8770949  -0.7071781  ...  1.8962716   0.5994188\n",
            "    -3.1098557 ]\n",
            "   ...\n",
            "   [-0.6014499  -1.9564679  -0.6420423  ...  1.9416889   0.68603057\n",
            "    -3.2526336 ]\n",
            "   [-0.6712451  -1.9979703  -0.7081382  ...  2.0044334   0.60271394\n",
            "    -3.3210683 ]\n",
            "   [-0.6593119  -1.9569998  -0.6733205  ...  1.9761432   0.63253146\n",
            "    -3.3265448 ]]\n",
            "\n",
            "  [[-0.58163476 -1.8401774  -0.6189652  ...  1.8576417   0.6246532\n",
            "    -3.1390562 ]\n",
            "   [-0.58848256 -1.8707771  -0.6186001  ...  1.8646604   0.58903474\n",
            "    -3.110773  ]\n",
            "   [-0.5907047  -1.884927   -0.61069196 ...  1.8609517   0.5795107\n",
            "    -3.1717892 ]\n",
            "   ...\n",
            "   [-0.6518948  -1.9749544  -0.6760113  ...  1.9661912   0.64413685\n",
            "    -3.297463  ]\n",
            "   [-0.64877015 -1.9419286  -0.6651621  ...  1.9919108   0.6116672\n",
            "    -3.325818  ]\n",
            "   [-0.6301169  -1.9358406  -0.65948176 ...  1.9733392   0.6648214\n",
            "    -3.2792249 ]]\n",
            "\n",
            "  [[-0.59832543 -1.8820729  -0.6666096  ...  1.8629533   0.6726906\n",
            "    -3.1035361 ]\n",
            "   [-0.6775593  -1.82708    -0.6519261  ...  1.8983196   0.5398706\n",
            "    -3.1611385 ]\n",
            "   [-0.5495005  -1.8351862  -0.6347794  ...  1.8864509   0.6742232\n",
            "    -3.1266522 ]\n",
            "   ...\n",
            "   [-0.6488277  -1.9480242  -0.6953098  ...  2.006361    0.6496838\n",
            "    -3.3102489 ]\n",
            "   [-0.64184815 -1.9413671  -0.65585315 ...  1.9758595   0.6386641\n",
            "    -3.296071  ]\n",
            "   [-0.62195307 -1.9753399  -0.66089225 ...  1.9669694   0.6571211\n",
            "    -3.2956133 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.31085184 -0.9893138  -0.30267283 ...  1.5548711  -0.45945483\n",
            "    -2.8992863 ]\n",
            "   [-0.00663744 -1.6259348  -0.06620385 ...  1.3039575   0.9564317\n",
            "    -2.8829145 ]\n",
            "   [-0.6631074  -1.8904591  -0.61938596 ...  1.8357671   0.59105855\n",
            "    -3.1630101 ]\n",
            "   ...\n",
            "   [-0.7801113  -1.7519385  -0.80041003 ...  2.1034958   0.46327943\n",
            "    -3.0878239 ]\n",
            "   [-0.6140357  -1.9688053  -0.6793621  ...  1.9607829   0.656376\n",
            "    -3.263722  ]\n",
            "   [-0.6730521  -1.9568032  -0.6571003  ...  1.9584405   0.5752648\n",
            "    -3.3045979 ]]\n",
            "\n",
            "  [[ 0.32801375 -1.8464637   0.4344357  ...  0.8007196   0.543416\n",
            "    -3.4266987 ]\n",
            "   [-0.47254792 -1.7706733  -0.51512694 ...  1.7727813   0.80489886\n",
            "    -3.0900645 ]\n",
            "   [-0.6264528  -1.8247561  -0.66194123 ...  1.901815    0.6642859\n",
            "    -3.1354961 ]\n",
            "   ...\n",
            "   [-0.6601123  -1.8802178  -0.69142336 ...  1.9717361   0.287074\n",
            "    -3.2004356 ]\n",
            "   [-0.6759635  -1.9126596  -0.7023522  ...  1.9939588   0.5973653\n",
            "    -3.250002  ]\n",
            "   [-0.6245939  -1.8814094  -0.6877334  ...  2.003051    0.654773\n",
            "    -3.268557  ]]\n",
            "\n",
            "  [[-0.1323518  -1.4029522  -0.14440343 ...  1.4050266   1.3772979\n",
            "    -2.772534  ]\n",
            "   [-0.62206984 -2.001021   -0.58922344 ...  1.8814751   0.6679164\n",
            "    -3.303988  ]\n",
            "   [-0.58840287 -2.0169964  -0.53052235 ...  1.7511145   0.65352386\n",
            "    -3.231317  ]\n",
            "   ...\n",
            "   [-0.38867888 -1.6881164  -0.5864713  ...  1.8762507   0.4707984\n",
            "    -2.9870286 ]\n",
            "   [-0.67889553 -1.8738925  -0.6750384  ...  2.0022058   0.5156128\n",
            "    -3.2212052 ]\n",
            "   [-0.60150194 -1.9909427  -0.61846477 ...  1.9017427   0.63871974\n",
            "    -3.2554283 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool_model = Model(inputs=model.input, outputs=model.get_layer('max_pooling2d').output)\n",
        "pool_output = pool_model.predict(x)\n",
        "print(pool_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRDbo6AbPQh7",
        "outputId": "99f28a2c-8d1f-4e28-9f51-03cb1b7e110e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "[[[[-0.56538695 -1.8141849  -0.60731727 ...  1.8820368   0.63792825\n",
            "    -3.101766  ]\n",
            "   [-0.5907047  -1.8165774  -0.61069196 ...  1.8962716   0.65577745\n",
            "    -3.1098557 ]\n",
            "   [-0.57851535 -1.8205786  -0.5938122  ...  1.8995631   0.648266\n",
            "    -3.0975518 ]\n",
            "   ...\n",
            "   [-0.62914747 -1.9401385  -0.65625894 ...  2.0027602   0.6657796\n",
            "    -3.2915545 ]\n",
            "   [-0.6014499  -1.9006004  -0.6420423  ...  2.007493    0.68603057\n",
            "    -3.2526336 ]\n",
            "   [-0.6301169  -1.9358406  -0.65948176 ...  2.0044334   0.6648214\n",
            "    -3.2792249 ]]\n",
            "\n",
            "  [[-0.59832543 -1.7866449  -0.62989026 ...  1.9147402   0.6726906\n",
            "    -3.0910878 ]\n",
            "   [-0.5495005  -1.8351862  -0.6347794  ...  1.9186689   0.6742232\n",
            "    -3.0929317 ]\n",
            "   [-0.58590096 -1.8316262  -0.6132978  ...  1.9231056   0.654432\n",
            "    -3.1341562 ]\n",
            "   ...\n",
            "   [-0.60815156 -1.9310684  -0.6283335  ...  2.0176606   0.6538963\n",
            "    -3.2834167 ]\n",
            "   [-0.63249457 -1.9342227  -0.6529601  ...  2.006361    0.6496838\n",
            "    -3.2773361 ]\n",
            "   [-0.62195307 -1.9413671  -0.65585315 ...  2.0029027   0.6571211\n",
            "    -3.2946882 ]]\n",
            "\n",
            "  [[-0.54294544 -1.8340782  -0.5846422  ...  1.9197695   0.6537759\n",
            "    -3.099833  ]\n",
            "   [-0.54416853 -1.8621054  -0.591922   ...  1.9041408   0.6210355\n",
            "    -3.1478891 ]\n",
            "   [-0.6097695  -1.8449847  -0.6395367  ...  1.9217026   0.6244049\n",
            "    -3.180655  ]\n",
            "   ...\n",
            "   [-0.6411217  -1.9503908  -0.68150645 ...  2.0234835   0.6844423\n",
            "    -3.289929  ]\n",
            "   [-0.6371129  -1.9196689  -0.6539571  ...  2.0132108   0.6632703\n",
            "    -3.287057  ]\n",
            "   [-0.6215008  -1.9333944  -0.6460177  ...  2.0174956   0.6675847\n",
            "    -3.2717004 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.38082874 -0.725023   -0.01778462 ...  1.9178071   0.24401087\n",
            "    -2.1938267 ]\n",
            "   [-0.60126096 -1.8412374  -0.6419533  ...  1.9765083   0.6246495\n",
            "    -3.137948  ]\n",
            "   [-0.61370945 -1.8558543  -0.6381078  ...  1.9409454   0.61761254\n",
            "    -3.1474128 ]\n",
            "   ...\n",
            "   [-0.13470559 -1.1853217  -0.40285453 ...  1.8964609   0.49043775\n",
            "    -2.4436393 ]\n",
            "   [-0.6507086  -1.8106766  -0.69333965 ...  2.110805    0.6499007\n",
            "    -3.0874348 ]\n",
            "   [-0.6310286  -1.9304345  -0.6536199  ...  2.0042186   0.65418166\n",
            "    -3.262836  ]]\n",
            "\n",
            "  [[ 0.18561198 -0.9893138   0.13517496 ...  1.5548711   0.9564317\n",
            "    -2.5292263 ]\n",
            "   [-0.58296156 -1.8308812  -0.5931191  ...  1.8864087   0.6330078\n",
            "    -3.0949736 ]\n",
            "   [-0.59302515 -1.8363392  -0.62211025 ...  1.9437957   0.60574955\n",
            "    -3.0931926 ]\n",
            "   ...\n",
            "   [-0.04214654 -1.0204306  -0.2980174  ...  1.7676439   0.37227723\n",
            "    -1.9924273 ]\n",
            "   [-0.28611585 -1.5625764  -0.64401066 ...  2.1034958   0.6050491\n",
            "    -2.8992734 ]\n",
            "   [-0.6140357  -1.9154952  -0.6563054  ...  1.9844071   0.656376\n",
            "    -3.259276  ]]\n",
            "\n",
            "  [[ 0.32801375 -1.4029522   0.4344357  ...  1.8814751   1.3772979\n",
            "    -2.772534  ]\n",
            "   [-0.58840287 -1.8247561  -0.53052235 ...  1.9050713   0.6642859\n",
            "    -3.1209164 ]\n",
            "   [-0.58059675 -1.8416451  -0.6140391  ...  1.929049    0.62209004\n",
            "    -3.1438212 ]\n",
            "   ...\n",
            "   [-0.1862197  -1.0390838  -0.29983178 ...  1.5747882   0.2515445\n",
            "    -1.8568962 ]\n",
            "   [-0.08634768 -1.3971308  -0.483332   ...  1.9717361   0.4707984\n",
            "    -2.6669984 ]\n",
            "   [-0.60150194 -1.8738925  -0.61846477 ...  2.003051    0.654773\n",
            "    -3.2212052 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bn_model = Model(inputs=model.input, outputs=model.get_layer('batch_normalization').output)\n",
        "bn_output = bn_model.predict(x)\n",
        "print(bn_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFpNaQFBmosk",
        "outputId": "44ce9fa8-e881-49db-9504-3d0181e2af4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79454c039480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n",
            "[[[[-7.67134070e-01 -8.60825658e-01 -8.07629764e-01 ...  9.01398733e-02\n",
            "    -4.82812710e-02 -6.96215391e-01]\n",
            "   [-8.38218093e-01 -8.65473390e-01 -8.14993858e-01 ...  1.18994743e-01\n",
            "    -2.17981776e-03 -7.04599321e-01]\n",
            "   [-8.03994358e-01 -8.73245895e-01 -7.78159738e-01 ...  1.25666797e-01\n",
            "    -2.15805750e-02 -6.91847742e-01]\n",
            "   ...\n",
            "   [-9.46152985e-01 -1.10550046e+00 -9.14427817e-01 ...  3.34854335e-01\n",
            "     2.36539841e-02 -8.92909825e-01]\n",
            "   [-8.68387222e-01 -1.02869475e+00 -8.83404911e-01 ...  3.44448119e-01\n",
            "     7.59588107e-02 -8.52572739e-01]\n",
            "   [-9.48874772e-01 -1.09715164e+00 -9.21460509e-01 ...  3.38246047e-01\n",
            "     2.11791173e-02 -8.80131662e-01]]\n",
            "\n",
            "  [[-8.59614670e-01 -8.07327092e-01 -8.56887400e-01 ...  1.56431884e-01\n",
            "     4.15038802e-02 -6.85148537e-01]\n",
            "   [-7.22530127e-01 -9.01622474e-01 -8.67556214e-01 ...  1.64395541e-01\n",
            "     4.54623476e-02 -6.87059581e-01]\n",
            "   [-8.24730754e-01 -8.94706726e-01 -8.20680201e-01 ...  1.73389092e-01\n",
            "    -5.65490453e-03 -7.29784131e-01]\n",
            "   ...\n",
            "   [-8.87203276e-01 -1.08788121e+00 -8.53490293e-01 ...  3.65058541e-01\n",
            "    -7.03858677e-03 -8.84476066e-01]\n",
            "   [-9.55550551e-01 -1.09400868e+00 -9.07229304e-01 ...  3.42153460e-01\n",
            "    -1.79187600e-02 -8.78174126e-01]\n",
            "   [-9.25953448e-01 -1.10788727e+00 -9.13542330e-01 ...  3.35143328e-01\n",
            "     1.29064894e-03 -8.96157682e-01]]\n",
            "\n",
            "  [[-7.04125583e-01 -8.99469972e-01 -7.58149266e-01 ...  1.66626647e-01\n",
            "    -7.34956423e-03 -6.94211960e-01]\n",
            "   [-7.07559586e-01 -9.53915000e-01 -7.74034917e-01 ...  1.34946227e-01\n",
            "    -9.19123143e-02 -7.44016767e-01]\n",
            "   [-8.91745985e-01 -9.20656621e-01 -8.77937317e-01 ...  1.70545176e-01\n",
            "    -8.32097530e-02 -7.77974963e-01]\n",
            "   ...\n",
            "   [-9.79772747e-01 -1.12541652e+00 -9.69521701e-01 ...  3.76861930e-01\n",
            "     7.18565285e-02 -8.91225219e-01]\n",
            "   [-9.68517423e-01 -1.06573677e+00 -9.09404933e-01 ...  3.56038392e-01\n",
            "     1.71729047e-02 -8.88248682e-01]\n",
            "   [-9.24683630e-01 -1.09239972e+00 -8.92079771e-01 ...  3.64724100e-01\n",
            "     2.83163246e-02 -8.72333348e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.88953388e+00  1.25495827e+00  4.78818744e-01 ...  1.62648693e-01\n",
            "    -1.06570256e+00  2.44762644e-01]\n",
            "   [-8.67856681e-01 -9.13377345e-01 -8.83210719e-01 ...  2.81639904e-01\n",
            "    -8.25779438e-02 -7.33713925e-01]\n",
            "   [-9.02808011e-01 -9.41771746e-01 -8.74819279e-01 ...  2.09551558e-01\n",
            "    -1.00753278e-01 -7.43523121e-01]\n",
            "   ...\n",
            "   [ 4.42080051e-01  3.60791296e-01 -3.61461431e-01 ...  1.19378470e-01\n",
            "    -4.29224074e-01 -1.41402865e-02]\n",
            "   [-1.00668967e+00 -8.54010463e-01 -9.95343447e-01 ...  5.53868592e-01\n",
            "    -1.73585378e-02 -6.81362569e-01]\n",
            "   [-9.51434612e-01 -1.08664978e+00 -9.08668995e-01 ...  3.37810606e-01\n",
            "    -6.30148826e-03 -8.63146365e-01]]\n",
            "\n",
            "  [[ 1.34142828e+00  7.41552353e-01  8.12599480e-01 ... -5.73047221e-01\n",
            "     7.74358749e-01 -1.02841705e-01]\n",
            "   [-8.16477895e-01 -8.93259645e-01 -7.76647151e-01 ...  9.90019739e-02\n",
            "    -6.09898828e-02 -6.89175725e-01]\n",
            "   [-8.44733179e-01 -9.03862178e-01 -8.39910209e-01 ...  2.15329304e-01\n",
            "    -1.31393358e-01 -6.87329888e-01]\n",
            "   ...\n",
            "   [ 7.01956034e-01  6.81105494e-01 -1.32691145e-01 ... -1.41742259e-01\n",
            "    -7.34412491e-01  4.53490615e-01]\n",
            "   [ 1.69689674e-02 -3.72056097e-01 -8.87700260e-01 ...  5.39052367e-01\n",
            "    -1.33202568e-01 -4.86354291e-01]\n",
            "   [-9.03724134e-01 -1.05762887e+00 -9.14529145e-01 ...  2.97651321e-01\n",
            "    -6.33865537e-04 -8.59456778e-01]]\n",
            "\n",
            "  [[ 1.74124670e+00 -6.19733147e-02  1.46563125e+00 ...  8.90012309e-02\n",
            "     1.86138427e+00 -3.55002910e-01]\n",
            "   [-8.31755280e-01 -8.81361127e-01 -6.40051723e-01 ...  1.36832267e-01\n",
            "     1.97960380e-02 -7.16062546e-01]\n",
            "   [-8.09838235e-01 -9.14169312e-01 -8.22297812e-01 ...  1.85436815e-01\n",
            "    -8.91886503e-02 -7.39800811e-01]\n",
            "   ...\n",
            "   [ 2.97445059e-01  6.44870043e-01 -1.36650354e-01 ... -5.32673836e-01\n",
            "    -1.04624450e+00  5.93953550e-01]\n",
            "   [ 5.77853441e-01 -5.06648794e-02 -5.37075341e-01 ...  2.71966368e-01\n",
            "    -4.79949117e-01 -2.45627120e-01]\n",
            "   [-8.68533313e-01 -9.76812541e-01 -8.31955254e-01 ...  3.35443944e-01\n",
            "    -4.77416022e-03 -8.20000768e-01]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = model.get_layer('batch_normalization').get_weights()\n",
        "weight = a[0]/pow(a[3]+0.001, 0.5)\n",
        "bias = -(a[0]*a[2])/pow(a[3]+0.001, 0.5) + a[1]\n",
        "print(weight)\n",
        "print(bias)"
      ],
      "metadata": {
        "id": "aEb2O_otQov1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19942f4-b945-496c-b6f1-3ad0564b8980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.807677  1.9425796 2.18215   2.0206542 0.8150177 2.027068  2.5828292\n",
            " 1.0363885]\n",
            "[ 0.82028997  2.663373    0.51762754 -3.1442692   2.6822412  -3.7248764\n",
            " -1.695941    2.5184193 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bn_output_1 = np.zeros((1,22,22,8))\n",
        "for i in range(22):\n",
        "  for j in range(22):\n",
        "    for k in range(8):\n",
        "      bn_output_1[0][i][j][k] = pool_output[0][i][j][k]*weight[k]+bias[k]\n",
        "bn_output_1-bn_output"
      ],
      "metadata": {
        "id": "rltQ1QxdTwMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab4684f-f59d-41fd-f023-674a0dcaeb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 1.19209290e-07,  1.19209290e-07,  0.00000000e+00, ...,\n",
              "           2.30967999e-07,  7.82310963e-08, -2.38418579e-07],\n",
              "         [ 1.19209290e-07,  1.19209290e-07, -5.96046448e-08, ...,\n",
              "           2.08616257e-07,  7.59027898e-08, -5.96046448e-08],\n",
              "         [ 5.96046448e-08, -5.96046448e-08, -5.96046448e-08, ...,\n",
              "           5.96046448e-08, -1.86264515e-09, -5.96046448e-08],\n",
              "         ...,\n",
              "         [ 5.96046448e-08,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "           2.68220901e-07,  0.00000000e+00, -1.78813934e-07],\n",
              "         [ 1.19209290e-07,  1.19209290e-07,  0.00000000e+00, ...,\n",
              "          -2.98023224e-08,  3.72529030e-08, -1.78813934e-07],\n",
              "         [ 5.96046448e-08,  1.19209290e-07, -5.96046448e-08, ...,\n",
              "           2.98023224e-07,  8.19563866e-08, -5.96046448e-08]],\n",
              "\n",
              "        [[ 5.96046448e-08,  5.96046448e-08,  0.00000000e+00, ...,\n",
              "           2.98023224e-08,  2.60770321e-08, -1.78813934e-07],\n",
              "         [ 1.19209290e-07,  1.78813934e-07, -5.96046448e-08, ...,\n",
              "           2.98023224e-08,  2.23517418e-08, -5.96046448e-08],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "           1.04308128e-07,  9.26665962e-08, -1.19209290e-07],\n",
              "         ...,\n",
              "         [ 5.96046448e-08,  1.19209290e-07, -1.19209290e-07, ...,\n",
              "           3.57627869e-07, -6.51925802e-09, -1.19209290e-07],\n",
              "         [ 0.00000000e+00,  0.00000000e+00, -5.96046448e-08, ...,\n",
              "           8.94069672e-08,  5.40167093e-08, -1.78813934e-07],\n",
              "         [ 5.96046448e-08,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "           2.38418579e-07,  3.00351530e-08, -5.96046448e-08]],\n",
              "\n",
              "        [[ 5.96046448e-08,  1.19209290e-07, -5.96046448e-08, ...,\n",
              "           4.47034836e-08,  7.31088221e-08,  0.00000000e+00],\n",
              "         [ 1.19209290e-07,  1.19209290e-07,  0.00000000e+00, ...,\n",
              "           1.19209290e-07,  4.47034836e-08, -1.19209290e-07],\n",
              "         [ 5.96046448e-08, -5.96046448e-08, -5.96046448e-08, ...,\n",
              "           1.63912773e-07,  0.00000000e+00, -1.19209290e-07],\n",
              "         ...,\n",
              "         [ 5.96046448e-08,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "           1.19209290e-07,  8.94069672e-08, -1.19209290e-07],\n",
              "         [ 1.19209290e-07,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "           1.78813934e-07,  2.79396772e-08,  0.00000000e+00],\n",
              "         [ 5.96046448e-08,  1.19209290e-07, -1.19209290e-07, ...,\n",
              "           5.96046448e-08,  5.40167093e-08, -1.78813934e-07]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 2.38418579e-07, -1.19209290e-07,  8.94069672e-08, ...,\n",
              "           2.23517418e-07,  0.00000000e+00, -2.23517418e-07],\n",
              "         [ 5.96046448e-08,  5.96046448e-08,  0.00000000e+00, ...,\n",
              "           1.49011612e-07,  0.00000000e+00, -1.78813934e-07],\n",
              "         [ 5.96046448e-08,  0.00000000e+00,  5.96046448e-08, ...,\n",
              "           1.49011612e-08,  8.94069672e-08,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 1.19209290e-07, -8.94069672e-08, -2.98023224e-08, ...,\n",
              "           9.68575478e-08,  5.96046448e-08, -8.10250640e-08],\n",
              "         [ 0.00000000e+00,  1.19209290e-07, -5.96046448e-08, ...,\n",
              "           1.78813934e-07, -3.72529030e-09, -5.96046448e-08],\n",
              "         [ 1.19209290e-07,  1.19209290e-07, -5.96046448e-08, ...,\n",
              "          -8.94069672e-08,  8.52160156e-08, -1.78813934e-07]],\n",
              "\n",
              "        [[ 2.38418579e-07, -1.19209290e-07,  5.96046448e-08, ...,\n",
              "           5.96046448e-08,  0.00000000e+00, -1.49011612e-07],\n",
              "         [ 1.19209290e-07,  1.19209290e-07,  0.00000000e+00, ...,\n",
              "           1.49011612e-07,  2.60770321e-08, -1.19209290e-07],\n",
              "         [ 5.96046448e-08, -5.96046448e-08, -1.19209290e-07, ...,\n",
              "           1.04308128e-07,  4.47034836e-08, -1.19209290e-07],\n",
              "         ...,\n",
              "         [ 5.96046448e-08, -1.19209290e-07,  0.00000000e+00, ...,\n",
              "           2.98023224e-08,  5.96046448e-08, -1.19209290e-07],\n",
              "         [ 1.17346644e-07,  8.94069672e-08,  0.00000000e+00, ...,\n",
              "           1.19209290e-07,  1.49011612e-08, -5.96046448e-08],\n",
              "         [ 5.96046448e-08,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "          -2.98023224e-08,  2.97441147e-08,  0.00000000e+00]],\n",
              "\n",
              "        [[ 0.00000000e+00, -1.86264515e-08,  1.19209290e-07, ...,\n",
              "           1.86264515e-07, -1.19209290e-07, -2.08616257e-07],\n",
              "         [ 0.00000000e+00,  1.19209290e-07, -5.96046448e-08, ...,\n",
              "           2.08616257e-07, -2.42143869e-08,  0.00000000e+00],\n",
              "         [ 5.96046448e-08,  0.00000000e+00, -5.96046448e-08, ...,\n",
              "           1.49011612e-07,  7.45058060e-08, -1.19209290e-07],\n",
              "         ...,\n",
              "         [ 1.19209290e-07, -2.38418579e-07,  2.98023224e-08, ...,\n",
              "           0.00000000e+00,  1.19209290e-07, -1.78813934e-07],\n",
              "         [ 1.19209290e-07, -2.23517418e-08,  0.00000000e+00, ...,\n",
              "           8.94069672e-08,  0.00000000e+00, -4.47034836e-08],\n",
              "         [ 5.96046448e-08, -5.96046448e-08,  0.00000000e+00, ...,\n",
              "           2.98023224e-08,  6.65895641e-08, -1.19209290e-07]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}